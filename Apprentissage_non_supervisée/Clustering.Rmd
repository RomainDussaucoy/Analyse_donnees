---
title: "TD5 Exercice4"
author: "Romain Dussaucoy"
date: "04/04/2022"
output: html_document
---

Dans cet exemple, nous allons procéder à un clustering hiérarchique, un dendrogramme.
On commence par créé un jeux de données.\

```{r}
set.seed(0)
x=matrix (rnorm (50*2) , ncol =2)
x[1:25 ,1] = x[1:25 ,1] + 3
x[1:25 ,2] = x[1:25 ,2] - 4
head(x)
```

On cherche à comparer les clusterings en utilisant un linkage complet, moyen et simple.\

```{r}
hc.complete = hclust(dist(x), method="complete")
hc.average = hclust(dist(x), method="average")
hc.single = hclust(dist(x), method="single")
```

Puis on trace les dendrogrammes
```{r}
par(mfrow=c(1,3))
plot(hc.complete,main="Complete Linkage", xlab="", sub="", cex=.9)
plot(hc.average, main="Average Linkage", xlab="", sub="", cex=.9)
plot(hc.single, main="Single Linkage", xlab="", sub="", cex=.9)
```

On affiche les étiquettes de cluster pour chaque observations associé à une coupe. Pour chaque modèle on a coupé notre dendogramme quand il ne reste que deux branches.

```{r}
cutree(hc.complete, 2)
cutree(hc.average, 2)
cutree(hc.single, 2)
```

On remarque que les trois méthodes de clustering hiérarchiques donnent les mêmes résultats.\
On effectue une mise à l'échelle sur le clustering avec linkage complet.\
```{r}
xsc=scale(x)
plot(hclust(dist(xsc), method="complete"), main="Hierarchical Clustering with Scaled Features")
```

Comme prévue, on peut séparer notre ensemble de données en deux sous-ensembles.